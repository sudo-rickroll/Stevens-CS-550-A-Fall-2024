| **Question** | **Answer** | **References** |
| :---------  | :--------- | :--------- |
| Briefly explain each of several reasons for creating a cluster. Give an example of each reason | 1.    Horizontal Scaling: Clustering provides more computing power. <br/>Ex: If more VRam is required for running a certain ML model, machines can be clustered together to accommodate for the same. <br/><br/>2.	Redundancy: Fail-over clustering provides fault-tolerant systems. This prevents downtime and also helps with minimal to no downtime during disaster recovery. <br/>Ex: If a node fails due to a machine’s malfunctioning CPU, an alternate node in the cluster can handle the load. <br/><br/>3.    High-availability: Clustering offers for a vast geo-availability, where machines would be scattered across different regions, thus offering lower latency. <br/>Ex: A user in India can access a system in Asia or a region nearby to query a database. This would result in receiving the result faster than when trying to access a system that is in, let’s say Australia. <br/><br/>4.    Load-balancing: When there is high traffic, the processing could be distributed among multiple systems to avoid overloading a particular system. <br/>Ex: Multiple gateways could be created in Power BI to grant access to data to different teams in a large organization, so that all of them can access this data simultaneously. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| What is a “loosely coupled” computer system? How does it differ from a “tighly coupled” system? | Loosely coupled systems have components that can function independently. Whereas tightly coupled systems have interdependent components. Loosely-coupled systems are also called multicomputer systems. Some loosely coupled systems share a storage device resource or a small amount of memory that can be used to communicate between the different computers. The determining factor that distinguishes a loosely coupled system is the autonomy of each computer within the system complex or network. There are two basic methods of connecting loosely coupled computers. Clustered computers are connected directly together with a dedicated communication channel or link that passes messages between machines. The key to the cluster concept is that the cluster is designed to operate as a single autonomous system sharing a workload. Conversely, networked computers operate more independently. The data communication channel between networked machines is used primarily to exchange and share data and external resources, rather than to share the actual processing. | 1.    Harold, Bell. (2023, June 8). The Difference Between Tight Coupling and Loose Coupling [Blog post]. Retrieved from <https://www.nonamesecurity.com/learn/difference-between-tight-and-loose-coupling/> <br/><br/> 2.    Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. | 
| Explain the difference between a multi-cloud and a hybrid cloud. | Multi-cloud combines different public clouds together whereas hybrid-cloud combines a public cloud with private or on-premise systems.Multi-clouds do this to reduce reliance on a single cloud provider. Hybrid clouds are a form of multi-clouds. A hybrid cloud can become a true multi-cloud if it involves more that one public cloud. There are a number of advantages and a number of major risks to an organization for IT system architects to consider when making decisions about a system design involving services in the cloud. Multi-cloud systems provide for better scalability whereas hybrid clouds provide for better security. Multi-cloud allows businesses to adopt a variety of cloud solutions.<br/><br/>Some of the advantages:<br/><br/>1.	The client’s data center is simplified and the cost reduced. It is not necessary to provide, support, and maintain individual copies of software for every user, nor to develop software that is already available from a cloud service provider, nor to purchase software that is only occasionally needed. Hardware purchase, configuration, power management, and maintenance are all potentially reduced and simplified.<br/><br/>2.    Cloud services provide strong support for user collaboration, since multiple users can easily access the same software, databases, tools, and data files from the cloud.<br/><br/>3.    Properly designed, with the proper client applications, cloud services can be accessed on a wide variety of client equipment, fixed or mobile, thick or thin, from anywhere the Internet is available | 1.    Multi-cloud vs. hybrid cloud: What’s the difference? Retrieved September 12, 2024, from <https://www.couldflare.com/en-gb/learning/cloud/multicloud-vs-hybrid-cloud/><br/><br/>2.    Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley.<br/><br/>3.    Difference Between Multi-Cloud and Hybrid Cloud. (2023, May 03). Retrieved from <https://www.geeksforgeeks.org/difference-between-multi-cloud-and-hybrid-cloud/> |
| LMC - Explain the inner workings of the Little Man Computer and its relation with real life computers, including the basics of assembly instructions. | The original LMC was created by Dr. Stuart Madnick at MIT in 1965. In 1979, Dr. Madnick produced a new version of the LMC, with a slightly modified instruction set. It is a strength of the original model that it operates so similarly to a real computer that it is still an accurate representation of the way that computers work more than fifty-five years after its introduction.<br/>The LMC consists of a walled mailroom. Inside the mailroom are several objects: First, there is a series of one hundred mailboxes, each numbered with an address ranging from 00 to 99. This numbering system is chosen because each mailbox address can be represented by two digits, and this is the maximum number of mailboxes that can be represented by two decimal digits. Each mailbox is designed to hold a single slip of paper, upon which is written a three digit decimal number. The contents of a mailbox are not the same as the address of a mailbox.<br/><br/>1.    load instruction—opcode 5:  The Little Man walks over to the mailbox address specified in the instruction. He reads the three-digit number located in that mailbox, and then walks over to the calculator and punches that number into the calculator. The three-digit number in the mailbox is left unchanged, but of course the original number in the calculator is replaced by the new number.<br/><br/>2.	store instruction—opcode 3 : This instruction is the reverse of the load instruction. The Little Man walks over to the calculator and reads the number there. He writes that number on a slip of paper and puts it in the mailbox whose address was specified as the address part of the instruction. The number in the calculator is unchanged; the original number in the mailbox is replaced with the new value.<br/><br/>3.    add instruction—opcode 1 : This instruction is very similar to the load instruction. The Little Man walks over to the mailbox address specified in the instruction. He reads the three-digit number located in the mailbox and then walks over to the calculator and adds it to the number already in the calculator. The number in the mailbox is unchanged.<br/><br/>4.	subtract instruction—opcode 2 : This instruction is the same as the add instruction, except that the Little Man subtracts the mailbox value from the value in the calculator. The result of a subtraction can leave a negative value in the calculator.  For the purposes of this LMC model, it is assumed that the calculator holds and handles negative values correctly, and provides a minus sign as a flag to indicate that the value is negative. The Little Man cannot handle negative numbers outside of the calculator, however, because there is no provision in the model for storing the negative sign within the constraint of the three-digit number system used.<br/><br/>5.	input instruction—opcode 9, “address” 01 : The Little Man walks over to the in basket and picks up the slip of paper in the basket. He then walks over to the calculator and punches it into the calculator. The number is no longer in the basket, and the original calculator value has been replaced by the new number. If there are multiple slips of paper in the in basket, the Little Man picks them up in the order in which they were submitted, but each input instruction handles only a single slip of paper; other input values must await the execution of subsequent input instructions.<br/><br/>6.    output instruction—opcode 9, “address” 02 : The Little Man walks over to the calculator and writes down the number that he sees there on a slip of paper. He then walks over to the out basket and places the slip of paper there for the user outside the mailroom to retrieve. The original number in the calculator is unchanged. Each output instruction places a single slip of paper in the out basket. Multiple outputs will require the use of multiple output instructions. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| Explain grid computing? | Storage area networks (SANs) are used for large-scale file services, particularly when those services must be fault-tolerant and not susceptible to a file server being the single-point of failure. Cloud services provide a mechanism to increase computing power by allowing users the ability to purchase or lease additional computer capability in the increments they need, particularly when it is necessary to expand capability on extremely short notice. An alternative approach used to achieve large amounts of computing power for specialized projects utilizes spare CPU capability available when individual computers on a large network facility, such as the Internet, are working at less than full capacity. This technique is known as grid computing. However, there are certain issues with this which may need to be factored in, like - effective division of the workload, scheduling work, preventing interference with local processing, effective use of the results, and security and privacy for the client machines. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| Fetch-execute – What is the fetch-execution? | It is an instruction cycle. It is also called fetch-decode-execute cycle. It is followed by the CPU from boot-up until the computer has shut down so as to process instructions. It consists of three main stages – fetch, decode, and execute.<br/><br/>Fetch Stage: The next instruction is fetched from the memory address that is currently stored in the program counter and stored into the instruction register. At the end of the fetch operation, the PC points to the next instruction that will be read at the next cycle.<br/><br/>Decode stage: During this stage, the encoded instruction presented in the instruction register is interpreted by the decoder.<br/><br/>Execute Stage: The control unit of the CPU passes the decoded information as a sequence of control signals to the relevant functional units of the CPU to perform actions required by the instruction, such as reading values from registers, passing them to ALU to perform mathematical or logical functions on them, and writing the result back to a register.<br/><br/>Repeat Cycle: In addition, on most processors interrupts can occur. This will cause the CPU to jump to an interrupt service routine, execute that and then return. | Instruction cycle. Retrieved September 12, 2024, from <https://www.en.wikipedia.org/wiki/instruction_cycle/> |
| Stack - How the stack is permanently used through any subroutine call to better write code? | Stacks are an efficient way of storing intermediate data values during complex calculations. Stacks are also an excellent method for storing the return addresses and arguments from subroutine calls. Program routines that are recursive must “call themselves”. If the return addressed were to be stored in a fixed location as opposed to a stack, it may end up getting lost and the program will end up in an infinite loop. However, with stacks, the return addresses are pushed down, where the program will return on its way out from the subroutine call in the reverse order. Computers do not generally provide special memory for stack use, although many machines provide special stack instructions to simplify the bookkeeping task. Instead, the programmer sets aside one or more blocks of regular memory for this purpose. The “bottom” of the stack is a fixed memory location, and a stack pointer points to the “top” of the stack, that is, the most recent entry. Many instruction sets provide push and pop instructions as direct support for stacks, but stacks can be implemented easily without special instructions. Some computers also specify the use of a particular general-purpose register as a stack pointer register. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| What is a frame in virtual computer? What is the relationship between a program and pages? | Frames are blocks of memories. Usually, all the frames are of equal size, typically 1–4 KB. The exception, an alternative method called segmentation is rarely used. The size of the blocks is permanently set as a design parameter of the particular hardware architecture, based on a number of factors. The most important criterion for the block size is that it must correspond exactly to a particular number of address bits. This guarantees that every address within the block is expressed by the same number of digits. The number of blocks depends on the amount of memory installed in the machine, but can’t exceed the largest memory address possible. The blocks are numbered, starting from 0. Because the block size was selected to use a specific, fixed number of bits, an actual memory address consists simply of the block number concatenated with the address within the block. By selecting a frame size that corresponds exactly to a given number of digits, we can simply concatenate to get the whole address. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| DMA - How Direct Memory Access works and when it is useful to use it? | Direct Memory Access allows the transfer of blocks of data directly between an I/O device and memory. For most applications, it is impractical to transfer data to the CPU from a peripheral device using programmed I/O, even with interrupts. The data from disks, tapes, and flash memory are transferred only in blocks, and it does not make sense to execute a separate instruction for each piece of data in the block. It is also more reasonable to transfer blocks of data directly between a device’s I/O controller and memory, since most processing will also take place in blocks. This suggests bypassing the CPU registers, if possible, and then processing the block of data as a group, from memory. Computer systems provide a more efficient form of I/O that transfers block data directly between the I/O controller and computer memory, under control of the I/O controller. The transfer is initiated by a program in the CPU, using programmed I/O, but the CPU can then be bypassed for the remainder of the transfer. The I/O controller will notify the CPU with an interrupt when the transfer is complete. Once this has occurred, the data is in memory, ready for the program to use. This technique of I/O–memory data transfer is known as direct memory access, or more commonly, simply as DMA.| Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| Why the Von Neumann model is essential in understanding computers ? | The idea that the program instructions and data are both stored in memory while being processed is known as the stored program concept. This important concept is attributed primarily to the principals of Von Neuman architecture. In 1945, John von Neumann, a consultant on the ENIAC project, proposed a computer that included a number of significant improvements over the ENIAC design. The most important of these were <br/><br/>1.    A memory that would hold both programs and data, the so-called stored program concept. This solved the difficult problem of rewiring the control panels for changing programs on the ENIAC.<br/><br/>2.    Binary processing of data. This simplified the design of the computer and allowed the use of binary memory for both instructions and data. It also recognized the natural relationship between the ON/OFF nature of switches and calculation in the binary number system, using Boolean logic.<br/><br/>The CPU was to include ALU, memory, and CU components. The control unit read instructions from memory and executed them. A method of handling I/O through the control unit was also established. The instruction set contained instructions representing all the essential features of a modern computer. In other words, von Neumann’s machine contained every major feature considered essential to modern computer architecture. Modern computer architecture is still referred to as von Neumann architecture. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| What  is the fundamental purpose of operating system? What is the role of the file mamanger? | The operating system (OS) software component provides the basic functionality of the system by offering programs that operate, control, and support the fundamental resources of the computer. Those resources include both CPU and peripheral hardware, network services, application programs, short-term program and data storage for use while a program is executing, time in which to execute programs, and overall access to the system. The operating system programs make system resources available to the user(s), the user’s application programs, and to other application programs running on the computer. The operating system also provides and controls access to other, interconnected systems through its networking and clustering capabilities. Although the operating system programs are tailored to the specific hardware provided on a particular system, it is possible to offer different operating systems on a particular hardware platform and to offer the same operating system on different hardware platforms. The hardware and the operating system operate together architecturally to form a complete working individual computer environment. The operating system has two fundamental purposes: to control and operate the hardware in an efficient manner and to allow the “users” powerful access to the facilities of the machine by providing a variety of facilities and services. The file manager assures a consistent representation and interface for file manipulation across different devices, so these services provide the user with a more powerful and easier to use way to access his program applications. The overall effect is an increased emphasis on the user interface and new ways of working that are more oriented toward the work to be accomplished and less to the launching and manipulation of application programs. Although many of these tools are found in a “shell”, they are more tightly integrated into the operating system than was true of previous shells. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| Data - Please describe any TWO examples representing different formats of data used for still images (bitmap versus object images), video, audio and alphanumerical data. | 1.	As an example of a bitmap image storage format, consider the popular Graphics Interchange Format (GIF) method of storing images. GIF was first developed by CompuServe in 1987 as a proprietary format that would allow users of the online service to store and exchange bitmap images on a variety of different computing platforms. A second, more flexible, form of GIF was released in 1989. The later version, GIF89a, also allows a series of GIF images to be displayed sequentially at fixed time intervals to create “animated GIF images”. The GIF format is used extensively on the Web. GIF assumes the existence of a rectangular “screen” upon which is located one or more rectangular images of possibly different sizes. Areas not covered with images are painted with a background color. The format divides the picture information and data into a number of blocks, each of which describes different aspects of the image. The first block, called the header block, identifies the file as a GIF file and specifies the version of GIF that is being used. Following the header block is a logical screen–descriptor block, which identifies the width and height of the screen, describes an optional color table for the images on the screen (the palette), indicates the number of bits per color available, identifies the background screen color, and specifies the pixel aspect ratio. Each image within the screen is then stored in its own block, headed by an image– descriptor block. The image–descriptor block identifies the size and position of the image on the screen, and also allows for a palette specific to the particular image, if desired. The block also contains information that makes it possible to display individual images at different resolutions. The actual pixel data for the image follows. The pixel data is compressed, using an algorithm called LZW. LZW is called a lossless compression algorithm because it is reversible: the original data is restored exactly upon expansion.<br/><br/>2.    The PostScript page description language is an example of a format that can be used to store, transmit, display, and print object images. A page description is a list of procedures and statements that describe each of the objects on a page. PostScript embeds page descriptions within a programming language. Thus, an image consists of a program written in the PostScript language. The programming language is stored in ASCII or Unicode text form. Thus, PostScript files can be stored and transmitted as any other text file. An interpreter program in the computer or output device reads the PostScript language statements and uses them to create pages that can then be printed or displayed. The interpreter produces an image that is the same, regardless of the device it is displayed or printed on. Compensation for differences in device resolution and pixel shape is built into the interpreter. PostScript provides a large library of functions that facilitate every aspect of an object-based image. There are functions that draw straight lines, Bezier curves, and arcs of a circle, functions that join simple objects into more complex ones, translate an object to a different location on the page, scale or distort an object, rotate an object, and create the mirror image of an object, and functions that fill an object with a pattern, or adjust the width and color of a line. There are methods for building and calling procedures, and if-then-else and loop programming structures. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| CPU-memory – Explain  how the CPU and memory communicate. Concept of a register (including MAR/MDR). | A register is a single, permanent storage location within the CPU used for a particular, defined purpose. A register is used to hold a binary value temporarily for storage, for manipulation, and/or for simple calculations. Note that each register is wired within the CPU to perform its specific role. That is, unlike memory, where every address is just like every other address, each register serves a particular purpose. The register’s size, the way it is wired, and even the operations that take place in the register reflect the specific function that the register performs in the computer. Registers also differ from memory in that they are not addressed as a memory location would be, but instead are manipulated directly by the control unit during the execution of instructions. Registers may be as small as a single bit or as wide as several bytes, ranging usually from 1 to 128 bits. Registers are used in many different ways in a computer. Depending on the particular use of a register, a register may hold data being processed, an instruction being executed, a memory or I/O address to be accessed, or even special binary codes used for some other purpose, such as codes that keep track of the status of the computer or the conditions of calculations that may be used for conditional branch instructions. Some registers serve many different purposes, while others are designed to perform a single, specialized task. There are even registers specifically designed to hold a number in floating point format, or a set of related values representing a list or vector, such as multiple pixels in an image. Registers are basic working components of the CPU. Two registers, the memory address register and the memory data register, act as an interface between the CPU and memory. The memory data register is called the memory buffer register by some computer manufacturers.<br/><br/>The memory address register holds the address in the memory that is to be “opened” for data. The MAR is connected to a decoder that interprets the address and activates a single address line into the memory. There is a separate address line for each row of cells in the memory; thus, if there are n bits of addressing, there will be 2n address lines.<br/><br/>The memory data register is designed such that it is effectively connected to every cell in the memory unit. Each bit of the MDR is connected in a column to the corresponding bit of every location in memory. However, the addressing method assures that only a single row of cells is activated at any given time. Thus, the MDR only has access to the values in that single row. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| What is a real-time system? Describe the impact of a real-time system on the design of operating systems, paying particular note to the various components and algorithms to be used. | A real-time system is a computer system used primarily to measure external events that happen in “real time”; that is, the event, when it occurs, requires processing quickly because the data is of critical time-sensitive value. As an example, consider a computer system that monitors the coolant temperature from the core of a power plant nuclear reactor. The temperature is transmitted once a minute by a temperature measurement transducer to the computer. In this particular case, the transducer input is expected, and, when it occurs, requires immediate evaluation. It is reasonable to assume, however, that the computer system is to be used for other purposes; while theoretically it would be possible to read the transducer over and over until data arrives, (another example illustrating the inefficiency of polling), practically this makes little sense: it is obviously not desirable to tie up the CPU in an input loop waiting for the transducer data to arrive. This is a perfect application for interrupts. The transducer input is assigned to an interrupt. The interrupt service routine in this case is used to process the transducer input data. When the interrupt occurs, the interrupt routine evaluates the input. If everything is normal, the routine returns control to whatever the computer was doing. In an emergency, the interrupt routine would transfer control instead to the program that handles emergency situations.<br/><br/> Real-time systems are systems in which one or more processes must be able to access the CPU immediately when required. Real-time systems are used for applications in which one or more programs are measuring or controlling I/O devices that must respond within specific time restraints. A real-time system might be used to control instrumentation, such as the control rockets on a space flight, or to measure time-sensitive data, such as the periodic measurements of the temperature in a nuclear reactor. Although some real-time systems are created exclusively for a particular application, most are general-purpose multitasking systems that have been designed so that they can be used for other tasks except when the time-sensitive application is being executed. A real-time system could be viewed as a multitasking system in which the interrupts that cause execution of the real-time program or programs have very high priority, but in many cases, special effort is made to assure that the real-time program can operate within its required time restraints. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| I/O – Please list different types of Input/Output: Programmed I/O vs Interrupts and explain how they each work, as well as their advantages and disadvantages. | Input – Keyboard, Mouse, Buses, Camera, etc.<br/><br/>Output – Monitor, Speaker, etc.<br/><br/> In the simplest method for performing I/O, an I/O controller is connected to a pair of I/O registers in the CPU via a bus. The I/O data register serves the same role in the real CPU as the input and output baskets served in the Little Man Computer. Alternatively, one might view the I/O baskets as buffers, holding multiple inputs or outputs, with the I/O data register as the interface between the CPU and the buffer. The I/O operation is similar to that of the Little Man Computer. Input from the peripheral device is transferred from the I/O controller or buffer for that peripheral device one word at a time to the I/O data register and from there to an accumulator or general-purpose register under program control, just as occurred in the Little Man Computer. Similarly, individual words of output data pass from a register to the I/O data register where they can be read by the appropriate I/O controller, again under program control. Each instruction produces a single input or output. This method is known as programmed I/O.<br/><br/>Computers provide interrupt capability by providing one or more special control lines to the central processor known as interruptlines. For example, the standard I/O for a modern PC may contain as many as thirty-two interrupt lines, labeled IRQ0 through IRQ31. (IRQ stands for Interrupt ReQuest.) The messages sent to the computer on these lines are known as interrupts. The presence of a message on an interrupt line will cause the computer to suspend the program being executed and jump to a special interrupt processing program. Interrupt messages are triggered primarily by the various I/O controllers in the system. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| Discuss the network futures and services provided in the operating system. Which services are mandatory? Why? | With the exception of some specialized embedded systems, nearly all computers today are interconnected, directly or indirectly, into networks. (There is even a trend toward networking embedded computers: modern automobile computers routinely report maintenance problems to the service technician when you bring your car in for service—many cars even report problems wirelessly from the road to a service representative. And you may have heard of the refrigerator that calls an order in to an Internet grocery delivery service when food stocks are low.) The network and communications support facilities within the operating system carry out the functions required to make the system perform seamlessly in a networked and distributed environment.<br/><br/> Network and communication services within the operating system provide the communication software necessary to implement the features and facilities of Wi-Fi, wired Ethernet, and TCP/IP. Most systems also implement a substantial set of TCP/IP applications and extensions, including e-mail, remote login, Web services, streaming multimedia, voice over IP telephony (VoIP), secure networking across the Internet (called a virtual private network, or VPN), and more. Most modern systems also provide Bluetooth capability. Communications services within the operating system also provide the interface between the communication software and the OS I/O control system that provides access to the network. The I/O control system includes the software drivers for modems, network interface cards, wireless communication cards, and other devices that are used to connect the computer physically and electrically to the network or networks. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| What is a page in virtual storage? What is the relationship between program and pages? | Suppose we also divide a program into blocks, where each block in the program is the same size as a frame. The blocks in a program are called pages.<br/><br/> The number of pages in a program depends on the size of the program. Like frames, the number of pages is also constrained by the instruction set architecture, but it is not limited to the size of installed memory. Stated differently, a program can be larger than the amount of memory installed in a computer, and still execute successfully, although possibly slowly. Dynamic address translation is built into the CPU hardware of every modern computer, large and small. The hardware automatically and invisibly translates every individual address in a program (the virtual addresses) to a different corresponding physical location (the physical addresses). This allows the operating system’s program loader to place the pages of a program into any available frames of physical memory, page by page, noncontiguously, so that it is not necessary to find a contiguous space large enough to fit the entire program. Any page of any program can be placed into any available frame of physical memory. Since every frame is essentially independent, the only fragmentation will be the small amount of space left over at the end of the last page of each individual program | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |
| Explain how the shortest job algorithm can result in starvation? | The shortest job first (SJF) method will maximize throughput by selecting jobs that require only a small amount of CPU time. The short-term scheduler uses as its basis time estimates provided with the jobs when they are submitted. To prevent the user from lying, systems that use this algorithm generally inflict a severe penalty on jobs that run more than a small percentage over their estimate. Since short jobs will be pushed ahead of longer jobs, starvation is possible. When SJF is implemented, it generally includes a dynamic priority factor that raises the priority of jobs as they wait, until they reach a priority where they will be processed next regardless of length. Although SJF maximizes throughput, you might note that its turnaround time is particularly inconsistent, since the time required to complete a job depends entirely on the mix of the jobs submitted both before it, and possibly after it. | Englander, IRV., Wong, W. (2021). The Architecture of Computer Hardware, Systems Software, and Networking (6th ed.). Hoboken, NJ: Wiley. |





















